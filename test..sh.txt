#!/bin/bash

# Define input file path
input_file="input.csv"

# Define chunk size in lines (adjust as needed)
chunk_size=1000000

# Get total lines in the input file
total_lines=$(wc -l < "$input_file")

# Calculate number of chunks needed
chunks=$(( ($total_lines + $chunk_size - 1) / $chunk_size ))

# Function to process each chunk
process_chunk() {
    python3 <<EOF
import csv
import re
import os

def convert_value(value):
    if value.strip() == '':
        return 'NULL'
    else:
        return value

def process_row(row):
    # Identify and convert JSON-like structures in the row
    for i, value in enumerate(row):
        if re.match(r'\{.*\}', value):
            # Check if JSON contains key 'shipto'
            if 'shipto' in value:
                # Replace values with 'TESTING' if key is 'shipto'
                row[i] = '{{{}}}'.format(','.join(['{}:{}'.format(k.strip(), 'TESTING') for k, v in [item.split(':') for item in value[1:-1].split(',')]]))
            else:
                # Replace values with 'NULL' for other keys
                row[i] = '{{{}}}'.format(','.join(['{}:{}'.format(k.strip(), convert_value(v.strip())) for k, v in [item.split(':') for item in value[1:-1].split(',')]]))
    return row

# Get start and end line numbers
start_line = int("$1")
end_line = int("$2")

# Generate output file name based on start and end line numbers
output_file = "output_" + str(start_line) + "_" + str(end_line) + ".csv"

with open('$3', 'r', newline='') as infile, open(output_file, 'a', newline='') as outfile:
    reader = csv.reader(infile, delimiter='|')
    writer = csv.writer(outfile, delimiter='|')

    # Read input file until end line
    for idx, row in enumerate(reader, start=1):
        if idx >= start_line and idx <= end_line:
            row = process_row(row)
            writer.writerow(row)
        elif idx > end_line:
            break

print("Conversion completed. Output written to:", output_file)
EOF
}

# Process the input file in chunks
for ((i = 0; i < $chunks; i++)); do
    start=$((i * chunk_size + 1))
    end=$((start + chunk_size - 1))

    if [ $end -gt $total_lines ]; then
        end=$total_lines
    fi

    echo "Processing lines $start to $end..."
    sed -n "${start},${end}p;${end}q" "$input_file" | process_chunk "$start" "$end" "$input_file"
done
